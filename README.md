# teach-transformer-to-add
The subsequent version of the code, which is a refined variant aimed to instruct GPT2 on performing addition, has been adapted to meet the required specifications for successful execution within the Google Colab framework. This version has been tested and is operational. The credits for the code go to the team of [transformers-arithmetic](https://github.com/castorini/transformers-arithmetic)

## Citation


```bibtex
@inproceedings{al2023samdit,
  title={SAMDIT: Systematic Study of Adding Memory to Divided Input in the Transformer to Process Long Documents},
  author={Al Adel, Arij},
  booktitle={International Conference on Neuroinformatics},
  pages={93--101},
  year={2023},
  organization={Springer}
}
